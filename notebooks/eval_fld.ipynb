{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mila/k/kirill.neklyudov/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/mila/k/kirill.neklyudov/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/home/mila/k/kirill.neklyudov/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/home/mila/k/kirill.neklyudov/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR10\n",
    "from fld.datasets.ImageTensorDataset import ImageTensorDataset\n",
    "from fld.features.DINOv2FeatureExtractor import DINOv2FeatureExtractor\n",
    "from fld.metrics.FLD import FLD\n",
    "\n",
    "feature_extractor = DINOv2FeatureExtractor()\n",
    "\n",
    "train_feat = feature_extractor.get_features(CIFAR10(train=True, root=\"data\", download=True))\n",
    "test_feat = feature_extractor.get_features(CIFAR10(train=False, root=\"data\", download=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_samples(sample_dir):\n",
    "    all_samples = []\n",
    "    stats = glob.glob(os.path.join(sample_dir, \"samples_*.npz\"))\n",
    "    for stat_file in stats:\n",
    "        with open(stat_file, \"rb\") as fin:\n",
    "            stat = np.load(fin)\n",
    "            all_samples.append(stat['samples'].transpose((0,3,1,2)))\n",
    "    all_samples = np.concatenate(all_samples, axis=0)[:50_000]\n",
    "    return ImageTensorDataset(torch.tensor(all_samples))\n",
    "\n",
    "def get_fld(feats):\n",
    "  fld_vals = []\n",
    "  for _ in range(10):\n",
    "    fld_vals.append(FLD().compute_metric(train_feat, test_feat, feats))\n",
    "  return np.array(fld_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_joint_det = feature_extractor.get_features(get_samples('../checkpoint/temp_ab_joint_vf/eval/samples/'))\n",
    "feat_joint_stoch = feature_extractor.get_features(get_samples('../checkpoint/temp_ab_joint_vf/eval/samples_stoch/'))\n",
    "\n",
    "fld_joint_det = get_fld(feat_joint_det)\n",
    "fld_joint_stoch = get_fld(feat_joint_stoch)\n",
    "print(f\"FLD_joint_det: {fld_joint_det.mean():.3f}±{fld_joint_det.std():.3f}\")\n",
    "print(f\"FLD_joint_stoch: {fld_joint_stoch.mean():.3f}±{fld_joint_stoch.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "feat_a = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5294839/eval/samples'))\n",
    "feat_b = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5294900/eval/samples'))\n",
    "feat_a_stoch = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5294839/eval/samples_stoch'))\n",
    "feat_b_stoch = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5294900/eval/samples_stoch'))\n",
    "feat_joint_det = feature_extractor.get_features(get_samples('../checkpoint/cond_joint_vf/eval/samples/'))\n",
    "feat_joint_stoch = feature_extractor.get_features(get_samples('../checkpoint/cond_joint_vf/eval/samples_stoch/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "fld_a = get_fld(feat_a)\n",
    "fld_b = get_fld(feat_b)\n",
    "fld_a_stoch = get_fld(feat_a_stoch)\n",
    "fld_b_stoch = get_fld(feat_b_stoch)\n",
    "fld_joint_det = get_fld(feat_joint_det)\n",
    "fld_joint_stoch = get_fld(feat_joint_stoch)\n",
    "fld_mixed = get_fld(torch.concatenate([feat_a[:25_000],feat_b[:25_000]]))\n",
    "fld_mixed_stoch = get_fld(torch.concatenate([feat_a_stoch[:25_000],feat_b_stoch[:25_000]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLD_A: 6.824±0.086\n",
      "FLD_B: 7.059±0.130\n",
      "FLD_A_stoch: 6.263±0.112\n",
      "FLD_B_stoch: 6.302±0.160\n",
      "FLD_joint_det: 6.860±0.082\n",
      "FLD_joint_stoch: 6.195±0.082\n",
      "FLD_Mixed: 7.038±0.115\n",
      "FLD_Mixed_stoch: 6.269±0.151\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLD_A: {fld_a.mean():.3f}±{fld_a.std():.3f}\")\n",
    "print(f\"FLD_B: {fld_b.mean():.3f}±{fld_b.std():.3f}\")\n",
    "print(f\"FLD_A_stoch: {fld_a_stoch.mean():.3f}±{fld_a_stoch.std():.3f}\")\n",
    "print(f\"FLD_B_stoch: {fld_b_stoch.mean():.3f}±{fld_b_stoch.std():.3f}\")\n",
    "print(f\"FLD_joint_det: {fld_joint_det.mean():.3f}±{fld_joint_det.std():.3f}\")\n",
    "print(f\"FLD_joint_stoch: {fld_joint_stoch.mean():.3f}±{fld_joint_stoch.std():.3f}\")\n",
    "print(f\"FLD_Mixed: {fld_mixed.mean():.3f}±{fld_mixed.std():.3f}\")\n",
    "print(f\"FLD_Mixed_stoch: {fld_mixed_stoch.mean():.3f}±{fld_mixed_stoch.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional entire CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "feat_det = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5617628/eval/samples'))\n",
    "feat_stoch = feature_extractor.get_features(get_samples('/network/scratch/k/kirill.neklyudov/5617628/eval/samples_stoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    }
   ],
   "source": [
    "fld_det = get_fld(feat_det)\n",
    "fld_stoch = get_fld(feat_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLD_det: 8.059±0.116\n",
      "FLD_stoch: 7.508±0.112\n"
     ]
    }
   ],
   "source": [
    "print(f\"FLD_det: {fld_det.mean():.3f}±{fld_det.std():.3f}\")\n",
    "print(f\"FLD_stoch: {fld_stoch.mean():.3f}±{fld_stoch.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('torch-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "18eafbcfabef88e7a8ee68dd8a0f06f97910ce749137fd562d7ce320776793f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
