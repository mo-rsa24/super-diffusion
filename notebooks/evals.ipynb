{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 12:02:36.942077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-18 12:02:37.215399: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-18 12:02:37.298047: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 12:02:40.612937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mila/k/kirill.neklyudov/jax-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import orbax\n",
    "import flax\n",
    "import tensorflow as tf\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "import datasets\n",
    "\n",
    "from flax.training import checkpoints\n",
    "from models import utils as mutils\n",
    "from models import ddpm\n",
    "import eval_utils as eutils\n",
    "import evaluation\n",
    "import train_utils as tutils\n",
    "import diffrax\n",
    "from functools import partial\n",
    "from tqdm import trange\n",
    "from run_lib import init_model\n",
    "from dynamics import get_vpsde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.sm.cifar import vpsde as config\n",
    "config = config.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pools(sample_dir):\n",
    "    all_pools = []\n",
    "    stats = tf.io.gfile.glob(os.path.join(sample_dir, \"statistics_*.npz\"))\n",
    "    for stat_file in stats:\n",
    "        with tf.io.gfile.GFile(stat_file, \"rb\") as fin:\n",
    "            stat = np.load(fin)\n",
    "            all_pools.append(stat[\"pool_3\"])\n",
    "    all_pools = np.concatenate(all_pools, axis=0)[:config.eval.num_samples]\n",
    "    return all_pools\n",
    "\n",
    "def load_dataset_stats(config, eval=False):\n",
    "  \"\"\"Load the pre-computed dataset statistics.\"\"\"\n",
    "  suffix = 'test' if eval else 'train'\n",
    "  if config.data.dataset == 'CIFAR10':\n",
    "    filename = f'../assets/stats/cifar10_{suffix}_stats.npz'\n",
    "  else:\n",
    "    raise ValueError(f'Dataset {config.data.dataset} stats not found.')\n",
    "\n",
    "  with tf.io.gfile.GFile(filename, 'rb') as fin:\n",
    "    stats = np.load(fin)\n",
    "    return stats\n",
    "\n",
    "train_pools = load_dataset_stats(config, eval=False)\n",
    "test_pools = load_dataset_stats(config, eval=True)\n",
    "\n",
    "def get_fid(pools):\n",
    "    train_fid = evaluation.fid(train_pools[\"pool_3\"], pools)\n",
    "    test_fid = evaluation.fid(test_pools[\"pool_3\"], pools)\n",
    "    print(f'train FID: {train_fid}, test FID: {test_fid}', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID Uncond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools_det = get_pools('/network/scratch/k/kirill.neklyudov/5617628/eval/samples')\n",
    "pools_stoch = get_pools('/network/scratch/k/kirill.neklyudov/5617628/eval/samples_stoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FID: 6.0028710668863265, test FID: 8.321379992849277\n",
      "train FID: 3.4969647777767126, test FID: 5.67004534558804\n",
      "IS: [8.947068]\n",
      "IS: [9.142855]\n"
     ]
    }
   ],
   "source": [
    "get_fid(pools_det)\n",
    "get_fid(pools_stoch)\n",
    "get_IS(pools_det)\n",
    "get_IS(pools_stoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FID Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools_joint_det = get_pools('../checkpoint/inv_ab_joint_vf/eval/samples_stoch/')\n",
    "pools_joint_stoch = get_pools('../checkpoint/high_temp_disjoint_joint_vf/eval/samples_stoch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FID: 4.40918801546627, test FID: 6.471772195304419\n",
      "train FID: 4.0057497035083145, test FID: 6.075971518519671\n",
      "IS: [9.383149]\n",
      "IS: [9.4856415]\n"
     ]
    }
   ],
   "source": [
    "get_fid(pools_joint_det)\n",
    "get_fid(pools_joint_stoch)\n",
    "get_IS(pools_joint_det)\n",
    "get_IS(pools_joint_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pools_a = get_pools('/network/scratch/k/kirill.neklyudov/5294839/eval/samples')\n",
    "pools_b = get_pools('/network/scratch/k/kirill.neklyudov/5294900/eval/samples')\n",
    "pools_a_stoch = get_pools('/network/scratch/k/kirill.neklyudov/5294839/eval/samples_stoch')\n",
    "pools_b_stoch = get_pools('/network/scratch/k/kirill.neklyudov/5294900/eval/samples_stoch')\n",
    "pools_joint_det = get_pools('../checkpoint/cond_joint_vf/eval/samples/')\n",
    "pools_joint_stoch = get_pools('../checkpoint/cond_joint_vf/eval/samples_stoch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FID: 5.298048498542919, test FID: 7.583245178049728\n",
      "train FID: 4.684625393252006, test FID: 6.7744546936673915\n",
      "train FID: 2.834219423529825, test FID: 4.983764363001981\n",
      "train FID: 4.857014731474025, test FID: 6.911617939993418\n",
      "train FID: 4.032961132269818, test FID: 6.2216255184786675\n",
      "train FID: 3.4742407122197836, test FID: 5.585484557959523\n"
     ]
    }
   ],
   "source": [
    "get_fid(pools_a)\n",
    "get_fid(pools_b)\n",
    "get_fid(pools_a_stoch)\n",
    "get_fid(pools_b_stoch)\n",
    "get_fid(pools_joint_det)\n",
    "get_fid(pools_joint_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 21:23:18.008910: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.6.68). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train FID: 19.805255889892578, test FID: 21.804908752441406\n",
      "train FID: 4.090967178344727, test FID: 6.273442268371582\n",
      "train FID: 3.55703067779541, test FID: 5.653024673461914\n"
     ]
    }
   ],
   "source": [
    "pools_mixed = jnp.vstack([pools_a, pools_b])\n",
    "get_fid(pools_mixed[::2])\n",
    "pools_mixed = jnp.vstack([pools_a[:25000], pools_b[:25000]])\n",
    "get_fid(pools_mixed)\n",
    "pools_mixed_stoch = jnp.vstack([pools_a_stoch[:25000], pools_b_stoch[:25000]])\n",
    "get_fid(pools_mixed_stoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_shape=(299, 299, 3),\n",
    "    pooling='avg')\n",
    "\n",
    "def get_IS(pools):\n",
    "    def h(p):\n",
    "        return -(jnp.log(p)*p).sum(1)\n",
    "    W,b = model.layers[-1].get_weights()\n",
    "    probs = jax.nn.softmax(pools@W + b)\n",
    "    IS = jnp.exp(h(probs.mean(0,keepdims=True)) - h(probs).mean())\n",
    "    print(f'IS: {IS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS: [10.851412]\n",
      "IS: [3.3749776]\n"
     ]
    }
   ],
   "source": [
    "get_IS(train_pools['pool_3'])\n",
    "get_IS(jax.random.normal(jax.random.PRNGKey(1), shape=train_pools['pool_3'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IS cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS: [9.042656]\n",
      "IS: [9.149275]\n",
      "IS: [9.444546]\n",
      "IS: [9.538941]\n",
      "IS: [9.061275]\n",
      "IS: [9.533243]\n"
     ]
    }
   ],
   "source": [
    "get_IS(pools_a)\n",
    "get_IS(pools_b)\n",
    "get_IS(pools_a_stoch)\n",
    "get_IS(pools_b_stoch)\n",
    "get_IS(pools_joint_det)\n",
    "get_IS(pools_joint_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS: [8.255488]\n",
      "IS: [9.13329]\n",
      "IS: [9.499198]\n"
     ]
    }
   ],
   "source": [
    "pools_mixed = jnp.vstack([pools_a, pools_b])\n",
    "get_IS(pools_mixed[::2])\n",
    "pools_mixed = jnp.vstack([pools_a[:25000], pools_b[:25000]])\n",
    "get_IS(pools_mixed)\n",
    "pools_mixed_stoch = jnp.vstack([pools_a_stoch[:25000], pools_b_stoch[:25000]])\n",
    "get_IS(pools_mixed_stoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 ('jax-env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b5010b7c43642655f9a773276a2f783938f8332af16a6f04f16ff491d6a6741"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
